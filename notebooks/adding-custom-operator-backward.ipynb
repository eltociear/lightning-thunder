{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f1f42d-f146-4c9c-8ed8-74f2bcf153f0",
   "metadata": {},
   "source": [
    "# Defining custom forward and backward for existing operators\n",
    "\n",
    "We are going to add custom executor for forward and backward of `torch.nn.functional.cross_entropy` operator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57fee1e",
   "metadata": {},
   "source": [
    "Here's `SoftmaxCrossEntropyLoss` definition from https://github.com/NVIDIA/apex/blob/master/apex/contrib/xentropy/softmax_xentropy.py:\n",
    "\n",
    "```py\n",
    "import torch\n",
    "\n",
    "import xentropy_cuda\n",
    "\n",
    "\n",
    "class SoftmaxCrossEntropyLoss(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, logits, labels, smoothing=0.0, padding_idx=0, half_to_float=False):\n",
    "        losses, max_log_sum_exp = xentropy_cuda.forward(\n",
    "            logits, labels, smoothing, half_to_float)\n",
    "        losses.masked_fill_(labels==padding_idx, 0)\n",
    "\n",
    "        ctx.save_for_backward(logits, max_log_sum_exp, labels,\n",
    "            torch.FloatTensor([smoothing]),\n",
    "            torch.LongTensor([padding_idx]))\n",
    "\n",
    "        return losses\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_loss):\n",
    "        logits, max_log_sum_exp, labels, smoothing, padding_idx = ctx.saved_tensors\n",
    "\n",
    "        if not grad_loss.is_contiguous():\n",
    "            grad_loss = grad_loss.contiguous()\n",
    "        grad_loss.masked_fill_(labels==padding_idx.item(), 0)\n",
    "        grad_logits = xentropy_cuda.backward(\n",
    "            grad_loss.contiguous(), logits, max_log_sum_exp,\n",
    "            labels, smoothing.item())\n",
    "\n",
    "        return grad_logits, None, None, None, None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576d267d-9cef-4414-a722-b2cef0665cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import thunder\n",
    "import torch\n",
    "\n",
    "from thunder.core.proxies import TensorProxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e16bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helper functions (execute this cell)\n",
    "import functools\n",
    "\n",
    "_indentation = 0\n",
    "def _log(msg=None):\n",
    "    \"\"\"Print a message at current indentation.\"\"\"\n",
    "    if msg is not None:\n",
    "        print(\"  \" * _indentation + msg)\n",
    "\n",
    "def _log_indent(msg=None):\n",
    "    \"\"\"Print a message and then indent the rest.\"\"\"\n",
    "    global _indentation\n",
    "    _log(msg)\n",
    "    _indentation = 2 + _indentation\n",
    "\n",
    "def _log_unindent(msg=None):\n",
    "    \"\"\"Unindent then print a message.\"\"\"\n",
    "    global _indentation\n",
    "    _indentation = _indentation - 2\n",
    "    _log(msg)\n",
    "  \n",
    "def log(func):\n",
    "    \"\"\"A decorator for functions to log arguments and results.\"\"\"\n",
    "    name = func.__name__\n",
    "    def pp(v):\n",
    "        \"\"\"Print certain values more succinctly\"\"\"\n",
    "        vtype = str(type(v))\n",
    "        if isinstance(v, tuple):\n",
    "            return \"({})\".format(pp_values(v))\n",
    "        elif isinstance(v, thunder.core.proxies.TensorProxy):\n",
    "            return f\"TensorProxy(name={v.name}, shape={v.shape}, dtype={v.dtype}, device={v.device})\"\n",
    "        elif isinstance(v, torch.Tensor):\n",
    "            return f\"Tensor(shape={v.shape}, stride={v.stride()}, dtype={v.dtype}, device={v.device}) with values {v}\"\n",
    "        else:\n",
    "            return str(v)\n",
    "    def pp_values(args):\n",
    "        return \", \".join([pp(arg) for arg in args])\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def func_wrapper(*args):\n",
    "        _log_indent(\"call {}({})\".format(name, pp_values(args)))\n",
    "        res = func(*args)\n",
    "        _log_unindent(\"|<- {} = {}\\n\".format(name, pp(res)))\n",
    "        return res\n",
    "\n",
    "    return func_wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c6260",
   "metadata": {},
   "source": [
    "We need to make `xentropy_cuda.forward` and `xentropy_cuda.backward` traceable by Thunder, for this we need to create corresponding Symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764c203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Symbol in module thunder.core.symbol:\n",
      "\n",
      "class Symbol(builtins.object)\n",
      " |  Symbol(name: 'str', meta: 'Callable | None' = None, python_impl: 'Callable | None' = None, id: 'Any | None' = None, is_prim: 'bool' = False, is_fusion: 'bool' = False, python_printer: 'Callable' = <function default_python_printer at 0x7f946b601a20>, _module: 'Any | None' = None, _hash: 'Optional[int]' = None, _bind_postprocess: 'None | Callable' = None, _phantom: 'bool' = False) -> None\n",
      " |  \n",
      " |  Symbol(name: 'str', meta: 'Callable | None' = None, python_impl: 'Callable | None' = None, id: 'Any | None' = None, is_prim: 'bool' = False, is_fusion: 'bool' = False, python_printer: 'Callable' = <function default_python_printer at 0x7f946b601a20>, _module: 'Any | None' = None, _hash: 'Optional[int]' = None, _bind_postprocess: 'None | Callable' = None, _phantom: 'bool' = False)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __eq__(self, other: 'Symbol') -> 'int'\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getstate__ = _dataclass_getstate(self)\n",
      " |      # _dataclass_getstate and _dataclass_setstate are needed for pickling frozen\n",
      " |      # classes with slots.  These could be slightly more performant if we generated\n",
      " |      # the code instead of iterating over fields.  But that can be a project for\n",
      " |      # another day, if performance becomes an issue.\n",
      " |  \n",
      " |  __hash__(self) -> 'int'\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, name: 'str', meta: 'Callable | None' = None, python_impl: 'Callable | None' = None, id: 'Any | None' = None, is_prim: 'bool' = False, is_fusion: 'bool' = False, python_printer: 'Callable' = <function default_python_printer at 0x7f946b601a20>, _module: 'Any | None' = None, _hash: 'Optional[int]' = None, _bind_postprocess: 'None | Callable' = None, _phantom: 'bool' = False) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__ = _dataclass_setstate(self, state)\n",
      " |  \n",
      " |  bind(self, *args, output, subsymbols=(), _call_ctx=None, **kwargs) -> 'BoundSymbol'\n",
      " |  \n",
      " |  name_with_module(self)\n",
      " |  \n",
      " |  normalize(self, *args, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  module\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  id\n",
      " |  \n",
      " |  is_fusion\n",
      " |  \n",
      " |  is_prim\n",
      " |  \n",
      " |  meta\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  python_impl\n",
      " |  \n",
      " |  python_printer\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_bind_postprocess': 'None | Callable', '_hash': 'O...\n",
      " |  \n",
      " |  __dataclass_fields__ = {'_bind_postprocess': Field(name='_bind_postpro...\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |  \n",
      " |  __match_args__ = ('name', 'meta', 'python_impl', 'id', 'is_prim', 'is_...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from thunder.core.symbol import Symbol\n",
    "\n",
    "help(Symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba10b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log\n",
    "def apex_xentropy_forward_meta(\n",
    "    a,\n",
    "    target,\n",
    "    weight=None,\n",
    "    size_average=None,\n",
    "    ignore_index=-100,\n",
    "    reduce=None,\n",
    "    reduction=\"mean\",\n",
    "    label_smoothing=0.0,\n",
    "):\n",
    "    max_log_sum_exp = TensorProxy(like=target)\n",
    "    if reduction == \"none\":\n",
    "        return TensorProxy(like=target), max_log_sum_exp\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid reduction: {reduction}\")\n",
    "\n",
    "xentropy_forward = Symbol(\n",
    "    id=\"xentropy_forward\",\n",
    "    name=\"xentropy_forward\",\n",
    "    meta=apex_xentropy_forward_meta,\n",
    "    is_prim=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f164c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log\n",
    "def apex_xentropy_backward_meta(\n",
    "    grad,\n",
    "    logits,\n",
    "    labels,\n",
    "    max_log_sum_exp,\n",
    "    smoothing,\n",
    "):\n",
    "    return TensorProxy(like=logits)\n",
    "\n",
    "xentropy_backward = Symbol(\n",
    "    id=\"xentropy_backward\",\n",
    "    name=\"xentropy_backward\",\n",
    "    meta=apex_xentropy_backward_meta,\n",
    "    is_prim=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "755f53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunder.core.transforms import register_augmented_forward\n",
    "\n",
    "@register_augmented_forward(\"torch.nn.functional.cross_entropy\")\n",
    "def apex_cross_entropy_forward_rule(\n",
    "    a,\n",
    "    target,\n",
    "    weight=None,\n",
    "    size_average=None,\n",
    "    ignore_index=-100,\n",
    "    reduce=None,\n",
    "    reduction=\"mean\",\n",
    "    label_smoothing=0.0,\n",
    "):\n",
    "    loss, max_log_sum_exp = xentropy_forward(\n",
    "        a,\n",
    "        target,\n",
    "        weight,\n",
    "        size_average,\n",
    "        ignore_index,\n",
    "        reduce,\n",
    "        reduction,\n",
    "        label_smoothing,\n",
    "    )\n",
    "    primal = loss\n",
    "    saved_for_backward = (a, target, max_log_sum_exp, reduction, label_smoothing)\n",
    "    return primal, saved_for_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0379bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunder.core.transforms import register_backward\n",
    "\n",
    "@register_backward(\"torch.nn.functional.cross_entropy\")\n",
    "def apex_cross_entropy_backward_rule(\n",
    "    logits,\n",
    "    labels,\n",
    "    max_log_sum_exp,\n",
    "    reduction,\n",
    "    smoothing,\n",
    "    grad,\n",
    "):\n",
    "    if reduction != \"none\":\n",
    "        raise ValueError(f\"Invalid reduction: {reduction}\")\n",
    "\n",
    "    grad_logits = xentropy_backward(\n",
    "        grad,\n",
    "        logits,\n",
    "        labels,\n",
    "        max_log_sum_exp,\n",
    "        smoothing,\n",
    "    )\n",
    "    return grad_logits, *([None] * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5da6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call apex_xentropy_forward_meta(TensorProxy(name=t0, shape=(2048, 50257), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(2048,), dtype=int64, device=cuda:0), None, None, -1, None, none, 0.0)\n",
      "|<- apex_xentropy_forward_meta = (TensorProxy(name=t4, shape=(2048,), dtype=int64, device=cuda:0), TensorProxy(name=t3, shape=(2048,), dtype=int64, device=cuda:0))\n",
      "\n",
      "call apex_xentropy_backward_meta(TensorProxy(name=t2, shape=(2048,), dtype=float32, device=cuda:0), TensorProxy(name=t0, shape=(2048, 50257), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(2048,), dtype=int64, device=cuda:0), TensorProxy(name=t3, shape=(2048,), dtype=int64, device=cuda:0), 0.0)\n",
      "|<- apex_xentropy_backward_meta = TensorProxy(name=t5, shape=(2048, 50257), dtype=float32, device=cuda:0)\n",
      "\n",
      "call apex_xentropy_forward_meta(TensorProxy(name=t0, shape=(2048, 50257), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(2048,), dtype=int64, device=cuda:0), None, None, -1, None, none, 0.0)\n",
      "|<- apex_xentropy_forward_meta = (TensorProxy(name=t4, shape=(2048,), dtype=int64, device=cuda:0), TensorProxy(name=t3, shape=(2048,), dtype=int64, device=cuda:0))\n",
      "\n",
      "call apex_xentropy_backward_meta(TensorProxy(name=t2, shape=(2048,), dtype=float32, device=cuda:0), TensorProxy(name=t0, shape=(2048, 50257), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(2048,), dtype=int64, device=cuda:0), TensorProxy(name=t3, shape=(2048,), dtype=int64, device=cuda:0), 0.0)\n",
      "|<- apex_xentropy_backward_meta = TensorProxy(name=t5, shape=(2048, 50257), dtype=float32, device=cuda:0)\n",
      "\n",
      "# import __main__ as __main__\n",
      "# import thunder as thunder\n",
      "# import thunder.core.devices as devices\n",
      "# import thunder.core.dtypes as dtypes\n",
      "# import thunder.core.prims as prims\n",
      "import torch\n",
      "\n",
      "@torch.no_grad()\n",
      "def wrapper(*args):\n",
      "  # args: \"Collection\" \n",
      "  t0, \\\n",
      "  t1, \\\n",
      "  = args\n",
      "  t2 = prims.full((2048,), 1, device=devices.Device(\"cuda:0\"), dtype=dtypes.float32)  # t2: \"cuda:0 f32[2048]\"\n",
      "  (t4, t3) = __main__.xentropy_forward(t0, t1, None, None, -1, None, \"none\", 0.0)\n",
      "  t5 = __main__.xentropy_backward(t2, t0, t1, t3, 0.0)  # t5: \"cuda:0 f32[2048, 50257]\"\n",
      "  return (t4, (t5, None))\n"
     ]
    }
   ],
   "source": [
    "from thunder.core.transforms import inline, value_and_grad\n",
    "from thunder import torch as ltorch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "logits = torch.randn([2048, 50257], device=\"cuda\")\n",
    "labels = torch.randint(0, 50257, [2048], device=\"cuda\")\n",
    "\n",
    "@inline\n",
    "@value_and_grad\n",
    "def fun(logits, labels):\n",
    "    return ltorch.cross_entropy(logits, labels, reduction=\"none\", ignore_index=-1)\n",
    "\n",
    "trace = thunder.trace()(fun, logits, labels)\n",
    "print(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cb3f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xentropy_cuda\n",
    "\n",
    "@log\n",
    "def apex_xentropy_forward_impl(\n",
    "    a,\n",
    "    target,\n",
    "    weight=None,\n",
    "    size_average=None,\n",
    "    ignore_index=-100,\n",
    "    reduce=None,\n",
    "    reduction=\"mean\",\n",
    "    label_smoothing=0.0,\n",
    "):\n",
    "    losses, max_log_sum_exp = xentropy_cuda.forward(a, target, label_smoothing, False)\n",
    "\n",
    "    if reduction == \"none\":\n",
    "        losses = losses.to(a.dtype)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid reduction: {reduction}\")\n",
    "\n",
    "    return losses, max_log_sum_exp\n",
    "\n",
    "@log\n",
    "def apex_xentropy_backward_impl(\n",
    "    grad,\n",
    "    logits,\n",
    "    labels,\n",
    "    max_log_sum_exp,\n",
    "    smoothing,\n",
    "):\n",
    "    return xentropy_cuda.backward(grad.contiguous(), logits, max_log_sum_exp, labels, smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7553cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "always_executable = lambda *args, **kwargs: True\n",
    "\n",
    "op_to_xentropy = {\n",
    "    \"xentropy_forward\": (\"xentropy_forward_impl\", always_executable, apex_xentropy_forward_impl),\n",
    "    \"xentropy_backward\": (\"xentropy_backward_impl\", always_executable, apex_xentropy_backward_impl),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab2e4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunder.executors import add_operator_executor\n",
    "\n",
    "add_operator_executor(\"xentropy\", op_to_xentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e234a47b",
   "metadata": {},
   "source": [
    "That's it! We have implemented our custom forward and backward for `torch.nn.functional.cross_entropy` operator. Let's test it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd18aa1",
   "metadata": {},
   "source": [
    "The trace looks correct, let's check whether we can compile and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf360c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfun = thunder.compile(fun, disable_preprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aef98360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call apex_xentropy_forward_meta(TensorProxy(name=t0, shape=(2048, 50257), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(2048,), dtype=int64, device=cuda:0), None, None, -1, None, none, 0.0)\n",
      "|<- apex_xentropy_forward_meta = (TensorProxy(name=t4, shape=(2048,), dtype=int64, device=cuda:0), TensorProxy(name=t3, shape=(2048,), dtype=int64, device=cuda:0))\n",
      "\n",
      "call apex_xentropy_backward_meta(TensorProxy(name=t2, shape=(2048,), dtype=float32, device=cuda:0), TensorProxy(name=t0, shape=(2048, 50257), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(2048,), dtype=int64, device=cuda:0), TensorProxy(name=t3, shape=(2048,), dtype=int64, device=cuda:0), 0.0)\n",
      "|<- apex_xentropy_backward_meta = TensorProxy(name=t5, shape=(2048, 50257), dtype=float32, device=cuda:0)\n",
      "\n",
      "call apex_xentropy_forward_meta(TensorProxy(name=t0, shape=(2048, 50257), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(2048,), dtype=int64, device=cuda:0), None, None, -1, None, none, 0.0)\n",
      "|<- apex_xentropy_forward_meta = (TensorProxy(name=t4, shape=(2048,), dtype=int64, device=cuda:0), TensorProxy(name=t3, shape=(2048,), dtype=int64, device=cuda:0))\n",
      "\n",
      "call apex_xentropy_backward_meta(TensorProxy(name=t2, shape=(2048,), dtype=float32, device=cuda:0), TensorProxy(name=t0, shape=(2048, 50257), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(2048,), dtype=int64, device=cuda:0), TensorProxy(name=t3, shape=(2048,), dtype=int64, device=cuda:0), 0.0)\n",
      "|<- apex_xentropy_backward_meta = TensorProxy(name=t5, shape=(2048, 50257), dtype=float32, device=cuda:0)\n",
      "\n",
      "call apex_xentropy_forward_impl(Tensor(shape=torch.Size([2048, 50257]), stride=(50257, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-0.9247, -0.4253, -2.6438,  ...,  0.4511,  0.2409,  1.9543],\n",
      "        [ 0.0076, -0.4908,  0.3657,  ...,  2.5072,  0.9047, -1.4305],\n",
      "        [-0.4410, -0.7614, -1.1172,  ...,  1.4340,  0.0295, -1.0458],\n",
      "        ...,\n",
      "        [ 1.6802,  0.0936,  1.7099,  ...,  0.0959,  0.0930,  0.5663],\n",
      "        [-0.3087,  0.6993,  0.2254,  ..., -0.1843, -0.5453,  0.4774],\n",
      "        [-0.8503,  0.6477,  0.8301,  ..., -1.2821,  1.1696, -0.6323]],\n",
      "       device='cuda:0'), Tensor(shape=torch.Size([2048]), stride=(1,), dtype=torch.int64, device=cuda:0) with values tensor([37607, 42437,  7122,  ..., 11933, 11365,  3493], device='cuda:0'), None, None, -1, None, none, 0.0)\n",
      "|<- apex_xentropy_forward_impl = (Tensor(shape=torch.Size([2048]), stride=(1,), dtype=torch.float32, device=cuda:0) with values tensor([11.0501, 11.1012, 12.6766,  ..., 11.8839, 11.0986, 11.5464],\n",
      "       device='cuda:0'), Tensor(shape=torch.Size([2048]), stride=(1,), dtype=torch.float32, device=cuda:0) with values tensor([11.3186, 11.3176, 11.3338,  ..., 11.3294, 11.3149, 11.3184],\n",
      "       device='cuda:0'))\n",
      "\n",
      "call apex_xentropy_backward_impl(Tensor(shape=torch.Size([2048]), stride=(1,), dtype=torch.float32, device=cuda:0) with values tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), Tensor(shape=torch.Size([2048, 50257]), stride=(50257, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-0.9247, -0.4253, -2.6438,  ...,  0.4511,  0.2409,  1.9543],\n",
      "        [ 0.0076, -0.4908,  0.3657,  ...,  2.5072,  0.9047, -1.4305],\n",
      "        [-0.4410, -0.7614, -1.1172,  ...,  1.4340,  0.0295, -1.0458],\n",
      "        ...,\n",
      "        [ 1.6802,  0.0936,  1.7099,  ...,  0.0959,  0.0930,  0.5663],\n",
      "        [-0.3087,  0.6993,  0.2254,  ..., -0.1843, -0.5453,  0.4774],\n",
      "        [-0.8503,  0.6477,  0.8301,  ..., -1.2821,  1.1696, -0.6323]],\n",
      "       device='cuda:0'), Tensor(shape=torch.Size([2048]), stride=(1,), dtype=torch.int64, device=cuda:0) with values tensor([37607, 42437,  7122,  ..., 11933, 11365,  3493], device='cuda:0'), Tensor(shape=torch.Size([2048]), stride=(1,), dtype=torch.float32, device=cuda:0) with values tensor([11.3186, 11.3176, 11.3338,  ..., 11.3294, 11.3149, 11.3184],\n",
      "       device='cuda:0'), 0.0)\n",
      "|<- apex_xentropy_backward_impl = Tensor(shape=torch.Size([2048, 50257]), stride=(50257, 1), dtype=torch.float32, device=cuda:0) with values tensor([[4.8175e-06, 7.9373e-06, 8.6335e-07,  ..., 1.9069e-05, 1.5453e-05,\n",
      "         8.5732e-05],\n",
      "        [1.2250e-05, 7.4421e-06, 1.7526e-05,  ..., 1.4919e-04, 3.0043e-05,\n",
      "         2.9079e-06],\n",
      "        [7.6961e-06, 5.5867e-06, 3.9138e-06,  ..., 5.0188e-05, 1.2320e-05,\n",
      "         4.2036e-06],\n",
      "        ...,\n",
      "        [6.4482e-05, 1.3193e-05, 6.6423e-05,  ..., 1.3224e-05, 1.3186e-05,\n",
      "         2.1166e-05],\n",
      "        [8.9521e-06, 2.4529e-05, 1.5271e-05,  ..., 1.0138e-05, 7.0661e-06,\n",
      "         1.9648e-05],\n",
      "        [5.1904e-06, 2.3216e-05, 2.7861e-05,  ..., 3.3704e-06, 3.9123e-05,\n",
      "         6.4548e-06]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out, (grad_logits, grad_labels) = cfun(logits, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155fbc27",
   "metadata": {},
   "source": [
    "Our logging shows that we have successfully compiled and run our custom forward and backward for `torch.nn.functional.cross_entropy` operator calling `xentropy_cuda.forward` and `xentropy_cuda.backward` respectively. Let's check the correctness of our implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d7eb420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error in logits grad: tensor(1.3970e-09, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Let's compute the gradients with respect to the logits using PyTorch's autograd and compare\n",
    "logits.requires_grad_(True)\n",
    "\n",
    "loss = torch.nn.functional.cross_entropy(logits, labels, reduction=\"none\", ignore_index=-1)\n",
    "logits.grad = None\n",
    "loss.sum().backward()\n",
    "\n",
    "print(\"Max error in logits grad:\", (grad_logits - logits.grad).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ead11",
   "metadata": {},
   "source": [
    "That's it! We have successfully implemented custom forward and backward for `torch.nn.functional.cross_entropy` operator using CUDA extension from Apex. The same approach can be used for any other operator. The key is to make forward and backward traceable by Thunder by creating corresponding Symbols and registering an executor for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec61cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
