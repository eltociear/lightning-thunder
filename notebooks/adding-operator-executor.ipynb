{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f1f42d-f146-4c9c-8ed8-74f2bcf153f0",
   "metadata": {},
   "source": [
    "# Adding an operator executor\n",
    "\n",
    "We are going to write a simple executor for `prims.add` function that calls NumPy's addition function. Our executor will be restricted to only work with inputs with certain properties. We will use the `add_operator_executor` function to create our executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576d267d-9cef-4414-a722-b2cef0665cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import thunder\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e16bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helper functions (execute this cell)\n",
    "import functools\n",
    "\n",
    "_indentation = 0\n",
    "def _log(msg=None):\n",
    "    \"\"\"Print a message at current indentation.\"\"\"\n",
    "    if msg is not None:\n",
    "        print(\"  \" * _indentation + msg)\n",
    "\n",
    "def _log_indent(msg=None):\n",
    "    \"\"\"Print a message and then indent the rest.\"\"\"\n",
    "    global _indentation\n",
    "    _log(msg)\n",
    "    _indentation = 2 + _indentation\n",
    "\n",
    "def _log_unindent(msg=None):\n",
    "    \"\"\"Unindent then print a message.\"\"\"\n",
    "    global _indentation\n",
    "    _indentation = _indentation - 2\n",
    "    _log(msg)\n",
    "  \n",
    "def log(func):\n",
    "    \"\"\"A decorator for functions to log arguments and results.\"\"\"\n",
    "    name = func.__name__\n",
    "    def pp(v):\n",
    "        \"\"\"Print certain values more succinctly\"\"\"\n",
    "        vtype = str(type(v))\n",
    "        if isinstance(v, tuple):\n",
    "            return \"({})\".format(pp_values(v))\n",
    "        elif isinstance(v, thunder.core.proxies.TensorProxy):\n",
    "            return f\"TensorProxy(name={v.name}, shape={v.shape}, dtype={v.dtype}, device={v.device})\"\n",
    "        elif isinstance(v, torch.Tensor):\n",
    "            return f\"Tensor(shape={v.shape}, stride={v.stride()}, dtype={v.dtype}, device={v.device}) with values {v}\"\n",
    "        else:\n",
    "            return str(v)\n",
    "    def pp_values(args):\n",
    "        return \", \".join([pp(arg) for arg in args])\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def func_wrapper(*args):\n",
    "        _log_indent(\"call {}({})\".format(name, pp_values(args)))\n",
    "        res = func(*args)\n",
    "        _log_unindent(\"|<- {} = {}\\n\".format(name, pp(res)))\n",
    "        return res\n",
    "\n",
    "    return func_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666fa494-21f5-4ed7-829e-f8648fddb13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our test function\n",
    "def fun(a, b):\n",
    "    return a + b * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edbf395f-9549-4ae3-957c-ba34fc956b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our test input\n",
    "a = torch.randn(2, 2, device=\"cuda\")\n",
    "b = torch.randn(2, 1, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f938dff7-bac6-4807-b79d-a16cb5c6d90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# import thunder as thunder\n",
      "# import thunder.torch as ltorch\n",
      "import torch\n",
      "\n",
      "@torch.no_grad()\n",
      "def fun(a, b):\n",
      "  # a: \"cuda:0 f32[2, 2]\" \n",
      "  # b: \"cuda:0 f32[2, 1]\" \n",
      "  t1 = ltorch.mul(b, a)  # t1: \"cuda:0 f32[2, 2]\"\n",
      "    # t0 = prims.broadcast_in_dim(b, [2, 2], (0, 1))  # t0: \"cuda:0 f32[2, 2]\"\n",
      "    # t1 = prims.mul(t0, a)  # t1: \"cuda:0 f32[2, 2]\"\n",
      "  t2 = ltorch.add(a, t1, alpha=None)  # t2: \"cuda:0 f32[2, 2]\"\n",
      "    # t2 = prims.add(a, t1)  # t2: \"cuda:0 f32[2, 2]\"\n",
      "  return t2\n"
     ]
    }
   ],
   "source": [
    "# Let's see first how this function is represented as a trace\n",
    "trace = thunder.trace()(fun, a, b)\n",
    "print(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb4818b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bound symbol with id=PrimIDs.UNPACK_TRIVIAL is represented in the trace as |# a: \"cuda:0 f32[2, 2]\" |\n",
      "Bound symbol with id=PrimIDs.UNPACK_TRIVIAL is represented in the trace as |# b: \"cuda:0 f32[2, 1]\" |\n",
      "Bound symbol with id=torch.mul is represented in the trace as |t1 = ltorch.mul(b, a)  # t1: \"cuda:0 f32[2, 2]\"\n",
      "  # t0 = prims.broadcast_in_dim(b, [2, 2], (0, 1))  # t0: \"cuda:0 f32[2, 2]\"\n",
      "  # t1 = prims.mul(t0, a)  # t1: \"cuda:0 f32[2, 2]\"|\n",
      "  It has the following subsymbols:\n",
      "    id=PrimIDs.BROADCAST_IN_DIM  |t0 = prims.broadcast_in_dim(b, [2, 2], (0, 1))  # t0: \"cuda:0 f32[2, 2]\"|\n",
      "    id=PrimIDs.MUL  |t1 = prims.mul(t0, a)  # t1: \"cuda:0 f32[2, 2]\"|\n",
      "Bound symbol with id=torch.add is represented in the trace as |t2 = ltorch.add(a, t1, alpha=None)  # t2: \"cuda:0 f32[2, 2]\"\n",
      "  # t2 = prims.add(a, t1)  # t2: \"cuda:0 f32[2, 2]\"|\n",
      "  It has the following subsymbols:\n",
      "    id=PrimIDs.ADD  |t2 = prims.add(a, t1)  # t2: \"cuda:0 f32[2, 2]\"|\n",
      "Bound symbol with id=PrimIDs.RETURN is represented in the trace as |return t2|\n"
     ]
    }
   ],
   "source": [
    "# We can loop over the recorded operations that we call BoundSymbols\n",
    "for bound_symbol in trace.bound_symbols:\n",
    "    print(f\"Bound symbol with id={bound_symbol.sym.id} is represented in the trace as |{bound_symbol}|\")\n",
    "    if bound_symbol.subsymbols:\n",
    "        print(\"  It has the following subsymbols:\")\n",
    "        for subsymbol in bound_symbol.subsymbols:\n",
    "            print(f\"    id={subsymbol.sym.id}  |{subsymbol}|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41566de2-a60f-4c87-a3d6-58e6a89dc38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function add_operator_executor in module thunder.executors:\n",
      "\n",
      "add_operator_executor(name, op_map, *, add_to_default_executors: bool = True) -> None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from thunder.executors import add_operator_executor\n",
    "\n",
    "help(add_operator_executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026680b3-7b46-4f4b-b16b-641fa9bdcdf4",
   "metadata": {},
   "source": [
    "The key argument here is `op_map`.\n",
    "\n",
    "`op_map` is a dictionary with the id of the operator we're providing executor for as a key and `(name, checker_fn, implementation_fn)` tuple as a value.\n",
    "\n",
    "* `name` is the name of our execution function that would be appearing in the execution trace.\n",
    "* `checker_fn` accepts the same set of arguments as the operator itself but returns `True` or `False` to signal to the executor orchestrator whether this particular set of inputs is supported or not.\n",
    "* `implementation_fn` accepts real PyTorch tensors and expected to return PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e02aaf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the addition function that can work only with NumPy's ndarrays\n",
    "\n",
    "@log\n",
    "def add_numpy(a, b):\n",
    "    assert isinstance(a, np.ndarray), \"a must be a NumPy ndarray\"\n",
    "    assert isinstance(b, np.ndarray), \"b must be a NumPy ndarray\"\n",
    "    return np.add(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ddbe12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need conversion functions from PyTorch to NumPy and back\n",
    "@log\n",
    "def torch_to_numpy(tensors):\n",
    "    return tuple(t.detach().cpu().numpy() for t in tensors)\n",
    "\n",
    "@log\n",
    "def numpy_to_torch(arrays, device):\n",
    "    return tuple(torch.from_numpy(arr).to(device) for arr in arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2460f808-eacb-4a0f-8f62-6a17e3dce6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log\n",
    "def checker_add_numpy(a, b):\n",
    "    # Suppose we only support float32 dtype, 2D, and (2, N) shape\n",
    "    first_condition = a.dtype == b.dtype == thunder.dtypes.float32\n",
    "    second_condition = a.ndim == b.ndim == 2\n",
    "    third_condition = a.shape[0] == b.shape[0] == 2\n",
    "    return first_condition and second_condition and third_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a61b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log\n",
    "def executor_add_numpy(a, b):\n",
    "    np_a, np_b = torch_to_numpy((a, b))\n",
    "    np_res = add_numpy(np_a, np_b)\n",
    "    res, = numpy_to_torch((np_res,), a.device)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502944e",
   "metadata": {},
   "source": [
    "Now we have all the pieces to create our executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7d3eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_map = {\n",
    "    thunder.prims.PrimIDs.ADD: (\"add_numpy\", checker_add_numpy, executor_add_numpy)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11f71c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's send our operator map to `add_operator_executor` to register our executor under the name \"custom_add_executor\"\n",
    "\n",
    "add_operator_executor(\"custom_add_executor\", op_map, add_to_default_executors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d864fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test our executor\n",
    "\n",
    "cfun = thunder.compile(fun, executors_list=[\"custom_add_executor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24af4b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find executor for bound symbol t1 = ltorch.mul(b, a)  # t1: \"cuda:0 f32[2, 2]\"\n",
      "  # t0 = prims.broadcast_in_dim(b, [2, 2], (0, 1))  # t0: \"cuda:0 f32[2, 2]\"\n",
      "  # t1 = prims.mul(t0, a)  # t1: \"cuda:0 f32[2, 2]\"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cfun(a, b)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d0c97",
   "metadata": {},
   "source": [
    "The above function errors out because we haven't provided an executor for `ltorch.mul` yet. Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ff48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfun = thunder.compile(fun, executors_list=[\"custom_add_executor\", thunder.executors.TORCH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1527d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call checker_add_numpy(TensorProxy(name=a, shape=(2, 2), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(2, 2), dtype=float32, device=cuda:0))\n",
      "|<- checker_add_numpy = True\n",
      "\n",
      "call checker_add_numpy(TensorProxy(name=a, shape=(2, 2), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(2, 2), dtype=float32, device=cuda:0))\n",
      "|<- checker_add_numpy = True\n",
      "\n",
      "call executor_add_numpy(Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-0.6906, -0.9761],\n",
      "        [ 0.9819, -0.1328]], device='cuda:0'), Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-1.3271, -1.8759],\n",
      "        [-0.2897,  0.0392]], device='cuda:0'))\n",
      "    call torch_to_numpy((Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-0.6906, -0.9761],\n",
      "        [ 0.9819, -0.1328]], device='cuda:0'), Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-1.3271, -1.8759],\n",
      "        [-0.2897,  0.0392]], device='cuda:0')))\n",
      "    |<- torch_to_numpy = ([[-0.6905969  -0.97613984]\n",
      " [ 0.98193294 -0.13276565]], [[-1.3271405  -1.8758768 ]\n",
      " [-0.28966585  0.03916528]])\n",
      "\n",
      "    call add_numpy([[-0.6905969  -0.97613984]\n",
      " [ 0.98193294 -0.13276565]], [[-1.3271405  -1.8758768 ]\n",
      " [-0.28966585  0.03916528]])\n",
      "    |<- add_numpy = [[-2.0177374  -2.8520167 ]\n",
      " [ 0.69226706 -0.09360038]]\n",
      "\n",
      "    call numpy_to_torch(([[-2.0177374  -2.8520167 ]\n",
      " [ 0.69226706 -0.09360038]]), cuda:0)\n",
      "    |<- numpy_to_torch = (Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-2.0177, -2.8520],\n",
      "        [ 0.6923, -0.0936]], device='cuda:0'))\n",
      "\n",
      "|<- executor_add_numpy = Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-2.0177, -2.8520],\n",
      "        [ 0.6923, -0.0936]], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0177, -2.8520],\n",
       "        [ 0.6923, -0.0936]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfun(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b5ed6",
   "metadata": {},
   "source": [
    "Our logging decorator shows us that the `checker_add_numpy` function got called twice with `TensorProxy` as arguments and both times the function returned `True`. This means that our executor is going to be used for this particular execution trace.\n",
    "\n",
    "Then we see that the `executor_add_numpy` function is called with regular PyTorch tensors as arguments and it returns a regular PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7ff30ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# Constructed by Delete Last Used\n",
       "# import torch as torch\n",
       "import torch\n",
       "\n",
       "@torch.no_grad()\n",
       "def fun(a, b):\n",
       "  # a: \"cuda:0 f32[2, 2]\" \n",
       "  # b: \"cuda:0 f32[2, 1]\" \n",
       "  t1 = torch.mul(b, a)  # t1: \"cuda:0 f32[2, 2]\"\n",
       "  del [b]\n",
       "  t2 = add_numpy(a, t1)  # t2: \"cuda:0 f32[2, 2]\"\n",
       "  del [a, t1]\n",
       "  return t2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check how our function is represented in the execution trace now\n",
    "thunder.last_traces(cfun)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0868c882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call executor_add_numpy(Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-0.6906, -0.9761],\n",
      "        [ 0.9819, -0.1328]], device='cuda:0'), Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-1.3271, -1.8759],\n",
      "        [-0.2897,  0.0392]], device='cuda:0'))\n",
      "    call torch_to_numpy((Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-0.6906, -0.9761],\n",
      "        [ 0.9819, -0.1328]], device='cuda:0'), Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-1.3271, -1.8759],\n",
      "        [-0.2897,  0.0392]], device='cuda:0')))\n",
      "    |<- torch_to_numpy = ([[-0.6905969  -0.97613984]\n",
      " [ 0.98193294 -0.13276565]], [[-1.3271405  -1.8758768 ]\n",
      " [-0.28966585  0.03916528]])\n",
      "\n",
      "    call add_numpy([[-0.6905969  -0.97613984]\n",
      " [ 0.98193294 -0.13276565]], [[-1.3271405  -1.8758768 ]\n",
      " [-0.28966585  0.03916528]])\n",
      "    |<- add_numpy = [[-2.0177374  -2.8520167 ]\n",
      " [ 0.69226706 -0.09360038]]\n",
      "\n",
      "    call numpy_to_torch(([[-2.0177374  -2.8520167 ]\n",
      " [ 0.69226706 -0.09360038]]), cuda:0)\n",
      "    |<- numpy_to_torch = (Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-2.0177, -2.8520],\n",
      "        [ 0.6923, -0.0936]], device='cuda:0'))\n",
      "\n",
      "|<- executor_add_numpy = Tensor(shape=torch.Size([2, 2]), stride=(2, 1), dtype=torch.float32, device=cuda:0) with values tensor([[-2.0177, -2.8520],\n",
      "        [ 0.6923, -0.0936]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's test whether the result is correct\n",
    "cfun_torch = thunder.compile(fun, executors_list=[thunder.executors.TORCH])\n",
    "expected = cfun_torch(a, b)\n",
    "actual = cfun(a, b)\n",
    "torch.testing.assert_close(expected, actual) # Should not raise an exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f978b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SampleInput args=(tensor([[-5.6039,  5.0201, -8.2948, -0.1738],\n",
      "        [ 8.4915, -2.8353, -7.4601, -4.3015],\n",
      "        [ 6.0777, -7.6420,  3.4135,  3.2371],\n",
      "        [-0.8413, -1.7334, -1.0025, -0.7366]], device='cuda:0'), tensor([[ 4.5391,  1.5542,  7.9208, -1.3760],\n",
      "        [-6.5864,  8.6491,  6.1823, -1.8481],\n",
      "        [ 7.9385, -0.4884,  4.2281,  1.3158],\n",
      "        [-4.6107,  3.5805,  3.1749, -4.5989]], device='cuda:0')) kwargs={}]\n"
     ]
    }
   ],
   "source": [
    "from thunder.tests.opinfos import add_opinfo\n",
    "\n",
    "sample = next(add_opinfo.sample_input_generator(add_opinfo, device=\"cuda\", dtype=torch.float32, requires_grad=False))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f07882f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call checker_add_numpy(TensorProxy(name=a, shape=(4, 4), dtype=float32, device=cuda:0), TensorProxy(name=t0, shape=(4, 4), dtype=float32, device=cuda:0))\n",
      "|<- checker_add_numpy = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's test whether the result is correct\n",
    "expected = cfun_torch(*sample.args)\n",
    "actual = cfun(*sample.args)\n",
    "torch.testing.assert_close(expected, actual) # Should not raise an exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "057689f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# Constructed by Delete Last Used\n",
       "# import torch as torch\n",
       "import torch\n",
       "\n",
       "@torch.no_grad()\n",
       "def fun(a, b):\n",
       "  # a: \"cuda:0 f32[2, 2]\" \n",
       "  # b: \"cuda:0 f32[2, 1]\" \n",
       "  t1 = torch.mul(b, a)  # t1: \"cuda:0 f32[2, 2]\"\n",
       "  del [b]\n",
       "  t2 = torch.add(a, t1)  # t2: \"cuda:0 f32[2, 2]\"\n",
       "  del [a, t1]\n",
       "  return t2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The order of executors matters today\n",
    "cfun_torch_first = thunder.compile(fun, executors_list=[thunder.executors.TORCH, \"custom_add_executor\"])\n",
    "cfun_torch_first(a, b)\n",
    "thunder.last_traces(cfun_torch_first)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2aca9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try inputs that are not supported by our executor\n",
    "a = torch.randn(3, 2, device=\"cuda\", dtype=torch.float64)\n",
    "b = torch.randn(3, 1, device=\"cuda\", dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b3e1589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call checker_add_numpy(TensorProxy(name=a, shape=(3, 2), dtype=float64, device=cuda:0), TensorProxy(name=t1, shape=(3, 2), dtype=float64, device=cuda:0))\n",
      "|<- checker_add_numpy = False\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "# Constructed by Delete Last Used\n",
       "# import torch as torch\n",
       "import torch\n",
       "\n",
       "@torch.no_grad()\n",
       "def fun(a, b):\n",
       "  # a: \"cuda:0 f64[3, 2]\" \n",
       "  # b: \"cuda:0 f64[3, 1]\" \n",
       "  t1 = torch.mul(b, a)  # t1: \"cuda:0 f64[3, 2]\"\n",
       "  del [b]\n",
       "  t2 = torch.add(a, t1)  # t2: \"cuda:0 f64[3, 2]\"\n",
       "  del [a, t1]\n",
       "  return t2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how our function is represented in the execution trace now with the new unsupported inputs\n",
    "cfun(a, b)\n",
    "thunder.last_traces(cfun)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ead11",
   "metadata": {},
   "source": [
    "That's it! We've created our first executor. The process is very similar for other existing operators. There are two ingridients that are required to create an executor:\n",
    "* `checker_fn` that checks whether the executor is applicable for a particular set of inputs (works with `TensorProxy` objects),\n",
    "* `implementation_fn` that implements the operator (works with regular PyTorch tensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec61cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
