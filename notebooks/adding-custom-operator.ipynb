{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f1f42d-f146-4c9c-8ed8-74f2bcf153f0",
   "metadata": {},
   "source": [
    "# Defining new Thunder operators\n",
    "\n",
    "We are going to add a new operator to Thunder with the corresponding executor. The operator will be called `sincos`` and will compute the sine and cosine of a given input.\n",
    "\n",
    "Thunder has three sets of core operators: `thunder.torch`, `thunder.clang`, and `thunder.prims`. `thunder.prims` is a set of operators that are implemented in Python and are used to build the other two sets of operators. A primitive is an operator that is not implemented in terms of other operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576d267d-9cef-4414-a722-b2cef0665cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import thunder\n",
    "import torch\n",
    "\n",
    "from thunder.core.proxies import TensorProxy\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e16bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helper functions (execute this cell)\n",
    "import functools\n",
    "\n",
    "_indentation = 0\n",
    "def _log(msg=None):\n",
    "    \"\"\"Print a message at current indentation.\"\"\"\n",
    "    if msg is not None:\n",
    "        print(\"  \" * _indentation + msg)\n",
    "\n",
    "def _log_indent(msg=None):\n",
    "    \"\"\"Print a message and then indent the rest.\"\"\"\n",
    "    global _indentation\n",
    "    _log(msg)\n",
    "    _indentation = 2 + _indentation\n",
    "\n",
    "def _log_unindent(msg=None):\n",
    "    \"\"\"Unindent then print a message.\"\"\"\n",
    "    global _indentation\n",
    "    _indentation = _indentation - 2\n",
    "    _log(msg)\n",
    "  \n",
    "def log(func):\n",
    "    \"\"\"A decorator for functions to log arguments and results.\"\"\"\n",
    "    name = func.__name__\n",
    "    def pp(v):\n",
    "        \"\"\"Print certain values more succinctly\"\"\"\n",
    "        vtype = str(type(v))\n",
    "        if isinstance(v, tuple):\n",
    "            return \"({})\".format(pp_values(v))\n",
    "        elif isinstance(v, thunder.core.proxies.TensorProxy):\n",
    "            return f\"TensorProxy(name={v.name}, shape={v.shape}, dtype={v.dtype}, device={v.device})\"\n",
    "        elif isinstance(v, torch.Tensor):\n",
    "            return f\"Tensor(shape={v.shape}, stride={v.stride()}, dtype={v.dtype}, device={v.device}) with values {v}\"\n",
    "        else:\n",
    "            return str(v)\n",
    "    def pp_values(args):\n",
    "        return \", \".join([pp(arg) for arg in args])\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def func_wrapper(*args):\n",
    "        _log_indent(\"call {}({})\".format(name, pp_values(args)))\n",
    "        res = func(*args)\n",
    "        _log_unindent(\"|<- {} = {}\\n\".format(name, pp(res)))\n",
    "        return res\n",
    "\n",
    "    return func_wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c6260",
   "metadata": {},
   "source": [
    "Our new operator has the following signature `sincos(x: Tensor) -> Tuple[Tensor, Tensor]`. It takes a tensor as input and returns a tuple of two tensors. The first tensor is the sine of the input and the second tensor is the cosine of the input.\n",
    "\n",
    "We call all callables that should be recorded in the trace Symbols. Symbols are the building blocks of the trace. Symbols are either primitives or composite operators. Composite perators are implemented in terms of other operators and primitives. Primitives are operators that are not implemented in terms of other operators or primitives.\n",
    "\n",
    "Let's create a new Symbol called `sincos` and implement it in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764c203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Symbol in module thunder.core.symbol:\n",
      "\n",
      "class Symbol(builtins.object)\n",
      " |  Symbol(name: 'str', meta: 'Callable | None' = None, python_impl: 'Callable | None' = None, id: 'Any | None' = None, is_prim: 'bool' = False, is_fusion: 'bool' = False, python_printer: 'Callable' = <function default_python_printer at 0x7f30f926dd80>, _module: 'Any | None' = None, _hash: 'Optional[int]' = None, _bind_postprocess: 'None | Callable' = None, _phantom: 'bool' = False) -> None\n",
      " |  \n",
      " |  Symbol(name: 'str', meta: 'Callable | None' = None, python_impl: 'Callable | None' = None, id: 'Any | None' = None, is_prim: 'bool' = False, is_fusion: 'bool' = False, python_printer: 'Callable' = <function default_python_printer at 0x7f30f926dd80>, _module: 'Any | None' = None, _hash: 'Optional[int]' = None, _bind_postprocess: 'None | Callable' = None, _phantom: 'bool' = False)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __eq__(self, other: 'Symbol') -> 'int'\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getstate__ = _dataclass_getstate(self)\n",
      " |      # _dataclass_getstate and _dataclass_setstate are needed for pickling frozen\n",
      " |      # classes with slots.  These could be slightly more performant if we generated\n",
      " |      # the code instead of iterating over fields.  But that can be a project for\n",
      " |      # another day, if performance becomes an issue.\n",
      " |  \n",
      " |  __hash__(self) -> 'int'\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, name: 'str', meta: 'Callable | None' = None, python_impl: 'Callable | None' = None, id: 'Any | None' = None, is_prim: 'bool' = False, is_fusion: 'bool' = False, python_printer: 'Callable' = <function default_python_printer at 0x7f30f926dd80>, _module: 'Any | None' = None, _hash: 'Optional[int]' = None, _bind_postprocess: 'None | Callable' = None, _phantom: 'bool' = False) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__ = _dataclass_setstate(self, state)\n",
      " |  \n",
      " |  bind(self, *args, output, subsymbols=(), _call_ctx=None, **kwargs) -> 'BoundSymbol'\n",
      " |  \n",
      " |  name_with_module(self)\n",
      " |  \n",
      " |  normalize(self, *args, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  module\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  id\n",
      " |  \n",
      " |  is_fusion\n",
      " |  \n",
      " |  is_prim\n",
      " |  \n",
      " |  meta\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  python_impl\n",
      " |  \n",
      " |  python_printer\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_bind_postprocess': 'None | Callable', '_hash': 'O...\n",
      " |  \n",
      " |  __dataclass_fields__ = {'_bind_postprocess': Field(name='_bind_postpro...\n",
      " |  \n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |  \n",
      " |  __match_args__ = ('name', 'meta', 'python_impl', 'id', 'is_prim', 'is_...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from thunder.core.symbol import Symbol\n",
    "\n",
    "help(Symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba10b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log\n",
    "def sincos_meta(input):\n",
    "    return (TensorProxy(like=input), TensorProxy(like=input))\n",
    "\n",
    "class CustomOps(Enum):\n",
    "    sincos = 0\n",
    "\n",
    "sincos = Symbol(\n",
    "    id=CustomOps.sincos,\n",
    "    name=\"sincos\",\n",
    "    meta=sincos_meta,\n",
    "    is_prim=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e234a47b",
   "metadata": {},
   "source": [
    "That's it! We have implemented our new primitive. Let's test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c5da6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(a, b):\n",
    "    sin, cos = sincos(a)\n",
    "    return sin + cos + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aef98360",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, device=\"cuda\")\n",
    "b = torch.randn(1, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6266dea4",
   "metadata": {},
   "source": [
    "`fun` is now a Thunder function, meaning it can only accept Thunder's TensorProxy as inputs. Let's test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87f9f6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find an eager implementation for sincos\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    fun(a, b)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dde0c4c",
   "metadata": {},
   "source": [
    "In the future we will add support for `torch.Tensor` and `numpy.ndarray` inputs for eager mode of Thunder functions. But for now this function is working only in the tracing mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f938dff7-bac6-4807-b79d-a16cb5c6d90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call sincos_meta(TensorProxy(name=a, shape=(1,), dtype=float32, device=cuda:0))\n",
      "|<- sincos_meta = (TensorProxy(name=t0, shape=(1,), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(1,), dtype=float32, device=cuda:0))\n",
      "\n",
      "# import __main__ as __main__\n",
      "# import thunder as thunder\n",
      "# import thunder.torch as ltorch\n",
      "import torch\n",
      "\n",
      "@torch.no_grad()\n",
      "def fun(a, b):\n",
      "  # a: \"cuda:0 f32[1]\" \n",
      "  # b: \"cuda:0 f32[1]\" \n",
      "  (t0, t1) = __main__.sincos(a)\n",
      "  t2 = ltorch.add(t0, t1, alpha=None)  # t2: \"cuda:0 f32[1]\"\n",
      "    # t2 = prims.add(t0, t1)  # t2: \"cuda:0 f32[1]\"\n",
      "  t3 = ltorch.add(t2, b, alpha=None)  # t3: \"cuda:0 f32[1]\"\n",
      "    # t3 = prims.add(t2, b)  # t3: \"cuda:0 f32[1]\"\n",
      "  return t3\n"
     ]
    }
   ],
   "source": [
    "# Let's see first how this function is represented as a trace\n",
    "trace = thunder.trace()(fun, a, b)\n",
    "print(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb4818b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bound symbol with id=PrimIDs.UNPACK_TRIVIAL is represented in the trace as |# a: \"cuda:0 f32[1]\" |\n",
      "Bound symbol with id=PrimIDs.UNPACK_TRIVIAL is represented in the trace as |# b: \"cuda:0 f32[1]\" |\n",
      "Bound symbol with id=CustomOps.sincos is represented in the trace as |(t0, t1) = __main__.sincos(a)|\n",
      "Bound symbol with id=torch.add is represented in the trace as |t2 = ltorch.add(t0, t1, alpha=None)  # t2: \"cuda:0 f32[1]\"\n",
      "  # t2 = prims.add(t0, t1)  # t2: \"cuda:0 f32[1]\"|\n",
      "  It has the following subsymbols:\n",
      "    id=PrimIDs.ADD  |t2 = prims.add(t0, t1)  # t2: \"cuda:0 f32[1]\"|\n",
      "Bound symbol with id=torch.add is represented in the trace as |t3 = ltorch.add(t2, b, alpha=None)  # t3: \"cuda:0 f32[1]\"\n",
      "  # t3 = prims.add(t2, b)  # t3: \"cuda:0 f32[1]\"|\n",
      "  It has the following subsymbols:\n",
      "    id=PrimIDs.ADD  |t3 = prims.add(t2, b)  # t3: \"cuda:0 f32[1]\"|\n",
      "Bound symbol with id=PrimIDs.RETURN is represented in the trace as |return t3|\n"
     ]
    }
   ],
   "source": [
    "# We can loop over the recorded operations that we call BoundSymbols\n",
    "for bound_symbol in trace.bound_symbols:\n",
    "    print(f\"Bound symbol with id={bound_symbol.sym.id} is represented in the trace as |{bound_symbol}|\")\n",
    "    if bound_symbol.subsymbols:\n",
    "        print(\"  It has the following subsymbols:\")\n",
    "        for subsymbol in bound_symbol.subsymbols:\n",
    "            print(f\"    id={subsymbol.sym.id}  |{subsymbol}|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2507d2",
   "metadata": {},
   "source": [
    "Let's see what happens if we try to compile a function that uses our new primitive and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41566de2-a60f-4c87-a3d6-58e6a89dc38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfun = thunder.compile(fun, disable_preprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbbb90c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call sincos_meta(TensorProxy(name=a, shape=(1,), dtype=float32, device=cuda:0))\n",
      "|<- sincos_meta = (TensorProxy(name=t0, shape=(1,), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(1,), dtype=float32, device=cuda:0))\n",
      "\n",
      "Could not find executor for bound symbol (t0, t1) = __main__.sincos(a)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cfun(a, b)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1fd6e3",
   "metadata": {},
   "source": [
    "There's no registered executor for `sincos` so we need to register an executor for our new primitive. Let's do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026680b3-7b46-4f4b-b16b-641fa9bdcdf4",
   "metadata": {},
   "source": [
    "Check out the \"adding-operator-executor.ipynb\" notebook to see how to implement an executor for a Symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2460f808-eacb-4a0f-8f62-6a17e3dce6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunder.executors import add_operator_executor\n",
    "\n",
    "@log\n",
    "def checker_sincos(a):\n",
    "    # We allow the sincos function to be called with any tensor\n",
    "    return True\n",
    "\n",
    "@log\n",
    "def executor_sincos(a):\n",
    "    return torch.sin(a), torch.cos(a)\n",
    "\n",
    "op_map = {\n",
    "    CustomOps.sincos: (\"sincos\", checker_sincos, executor_sincos)\n",
    "}\n",
    "\n",
    "add_operator_executor(\"sincos_executor\", op_map, add_to_default_executors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d864fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try again\n",
    "cfun = thunder.compile(fun, disable_preprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24af4b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call sincos_meta(TensorProxy(name=a, shape=(1,), dtype=float32, device=cuda:0))\n",
      "|<- sincos_meta = (TensorProxy(name=t0, shape=(1,), dtype=float32, device=cuda:0), TensorProxy(name=t1, shape=(1,), dtype=float32, device=cuda:0))\n",
      "\n",
      "call checker_sincos(TensorProxy(name=a, shape=(1,), dtype=float32, device=cuda:0))\n",
      "|<- checker_sincos = True\n",
      "\n",
      "call checker_sincos(TensorProxy(name=a, shape=(1,), dtype=float32, device=cuda:0))\n",
      "|<- checker_sincos = True\n",
      "\n",
      "call executor_sincos(Tensor(shape=torch.Size([1]), stride=(1,), dtype=torch.float32, device=cuda:0) with values tensor([-0.6296], device='cuda:0'))\n",
      "|<- executor_sincos = (Tensor(shape=torch.Size([1]), stride=(1,), dtype=torch.float32, device=cuda:0) with values tensor([-0.5889], device='cuda:0'), Tensor(shape=torch.Size([1]), stride=(1,), dtype=torch.float32, device=cuda:0) with values tensor([0.8082], device='cuda:0'))\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1889], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfun(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7ff30ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# Constructed by Delete Last Used\n",
       "import torch\n",
       "@torch.no_grad()\n",
       "def fun(a, b):\n",
       "  # a: \"cuda:0 f32[1]\" \n",
       "  # b: \"cuda:0 f32[1]\" \n",
       "  (t0, t1) = sincos(a)\n",
       "  del [a]\n",
       "  (t3,) = nvFusion0(b, t0, t1)\n",
       "    # t2 = prims.add(t0, t1)  # t2: \"cuda:0 f32[1]\"\n",
       "    # t3 = prims.add(t2, b)  # t3: \"cuda:0 f32[1]\"\n",
       "  del [b, t0, t1]\n",
       "  return t3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check how our function is represented in the execution trace now\n",
    "thunder.last_traces(cfun)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ead11",
   "metadata": {},
   "source": [
    "That's it! We've created our custom operator and registered an executor for it. To recap, we've done the following:\n",
    "* Created a new Symbol called `sincos` that represents the sine and cosine\n",
    "  computation (but not the actual computation itself). All we know about it is\n",
    "  that it takes a tensor as input and returns a tuple of two tensors. We gave this Symbol a name and id attributes to identify it in the trace and when processing the trace.\n",
    "* Implemented the actual computation by calling PyTorch's `sin` and `cos` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec61cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
