trigger:
  tags:
    include: ['*']
  branches:
    include: ["main"]
  paths:
    include:
      - ".azure/docker-build.yml"
      - "dockers/**"
      - "requirements.txt"
      - "requirements/*.txt"
      - "setup.py"
    exclude:
      - "*.md"
      - "**/*.md"

pr:
  branches:
    include: ['*']
  paths:
    include:
      - ".azure/docker-build.yml"
      - "dockers/**"
      - "requirements.txt"
      - "requirements/*.txt"
      - "setup.py"
    exclude:
      - "*.md"
      - "**/*.md"


jobs:
  - job: build_push
    strategy:
      matrix:
        'cuda 11.8 | torch 2.1 RC':
          CUDA_VERSION: '11.8.0'
          TORCH_BUILD: 'v2.1.0-rc6'
        'cuda 11.8 | torch 2.2 nightly':
          CUDA_VERSION: '11.8.0'
          TORCH_BUILD: 'main'
        #'cuda 12.1': # this version - '8.9.5.29-1+cuda12.1' for 'libcudnn8' was not found
        #  CUDA_VERSION: '12.1.1'
        'cuda 12.2 | torch 2.1 RC':
          CUDA_VERSION: '12.2.0'
          TORCH_BUILD: 'v2.1.0-rc6'
        'cuda 12.2 | torch 2.2 nightly':
          CUDA_VERSION: '12.2.0'
          TORCH_BUILD: 'main'
    # how long to run the job before automatically cancelling
    timeoutInMinutes: "95"
    # how much time to give 'run always even if cancelled tasks' before stopping them
    cancelTimeoutInMinutes: "2"
    variables:
      UBUNTU_VERSION: '22.04'
      PYTHON_VERSION: '3.10'
      imageRepository: 'pytorchlightning/lightning-thunder'
      dockerfilePath: 'dockers/ubuntu-cuda/Dockerfile'
      imageTag: 'ubuntu$(UBUNTU_VERSION)-cuda$(CUDA_VERSION)-py$(PYTHON_VERSION)-pt_${TORCH_BUILD}'
    pool: 'lit-rtx-3090'
    workspace:
      clean: all
    steps:
      #- task: DockerInstaller@0
      #  displayName: Docker Installer
      #  inputs:
      #    dockerVersion: 17.09.0-ce
      #    releaseType: stable

      - bash: |
          set -e
          docker image build \
            -t $(imageRepository):$(imageTag) \
            -f $(dockerfilePath) \
            --build-arg UBUNTU_VERSION=$(UBUNTU_VERSION) \
            --build-arg CUDA_VERSION=$(CUDA_VERSION) \
            --build-arg PYTHON_VERSION=$(PYTHON_VERSION) \
            --build-arg TORCH_CHECKOUT=$(TORCH_BUILD) \
            .
        displayName: 'Build base image'

      - bash: |
          docker image ls | grep $(imageRepository)
          docker run --rm --gpus=all $(imageRepository):$(imageTag) \
            python -c "import torch ; assert torch.cuda.is_available(), 'missing GPU support'"
        displayName: 'Sanity check'

      - bash: |
          set -e
          echo $(DOCKERHUB_PAT) | docker login --username $(DOCKERHUB_USER) --password-stdin
          docker push $(imageRepository):$(imageTag)
        condition: ne(variables['Build.Reason'], 'PullRequest')
        displayName: 'Push base image'

      #- task: Docker@1
      #  inputs:
      #    containerregistrytype: 'Container Registry'
      #    dockerRegistryEndpoint: 'Docker Hub'
      #    command: 'Build an image'
      #    dockerFile: '$(dockerfilePath)'
      #    imageName: '$(ImageName)'
      #    useDefaultContext: false
      #    buildContext: 'CustomerApi'
      #  displayName: 'Build the Docker image'
      #- task: Docker@1
      #  inputs:
      #    containerregistrytype: 'Container Registry'
      #    dockerRegistryEndpoint: 'Docker Hub'
      #    command: 'Push an image'
      #    imageName: '$(ImageName)'
      #  condition: and(succeeded(), ne(variables['Build.Reason'], 'PullRequest'))
      #  displayName: 'Push the Docker image to Dockerhub'
