import pytest
import torch
from looseversion import LooseVersion
from torch.testing import assert_close, make_tensor

import thunder
import thunder.core.dtypes as dtypes
import thunder.core.lang as tlang
import thunder.langs.torch as ttorch

from .framework import executors, ops, run_snippet
from .opinfos import opinfos

# Tests for all operators

# TODO: add error inputs tests (like test_elementwise_binary_prim_shape_mismatch and test_elementwise_binary_prim_dtype_mismatch)


# Snippets run a single test using a single sample
# TODO: should snippets be able to access the original opinfo? -- No?
def snippet_torch_consistency(op, torch_op, sample):
    thunder_result = op(*sample.args, **sample.kwargs)
    torch_result = torch_op(*sample.args, **sample.kwargs)

    assert_close(thunder_result, torch_result, equal_nan=True)


# TODO: consider structuring tests like this to be autogenerated
#   using a snippet and an "extractor" that constructs the args and kwargs for the snippet
@ops(tuple(op for op in opinfos if op.torch_reference is not None))
def test_core_vs_torch_consistency(op, device, dtype, executor):
    if LooseVersion(torch.__version__) < "1.13" and dtype is dtypes.complex32:
        pytest.skip("complex32 tests on PyTorch versions before 1.13 are skipped!")

    for sample in op.sample_inputs(device, dtype):
        result = run_snippet(
            snippet_torch_consistency,
            op,
            device,
            dtype,
            executor.make_callable(op.op),
            op.torch_reference,
            sample,
        )
        if result is not None:
            return result
